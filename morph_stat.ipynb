{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tim-Sa/text_diff_exp_notebook/blob/main/morph_stat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "205f5a5f-6111-4c1b-8e99-26c41eeb9633",
      "metadata": {
        "id": "205f5a5f-6111-4c1b-8e99-26c41eeb9633"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install natasha\n",
        "import natasha\n",
        "from razdel import sentenize, tokenize\n",
        "from ipymarkup import show_dep_ascii_markup as show_markup\n",
        "from navec import Navec\n",
        "from slovnet import Morph, Syntax\n",
        "from slovnet.markup import MorphMarkup, SyntaxMarkup\n",
        "\n",
        "import aiohttp\n",
        "\n",
        "import re\n",
        "from pprint import pprint\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установка и инициализация моделей синтаксического и морфологического анализа.\n",
        "[Проект Natasha](https://github.com/natasha)"
      ],
      "metadata": {
        "id": "uObRQUPjE9QU"
      },
      "id": "uObRQUPjE9QU"
    },
    {
      "cell_type": "code",
      "source": [
        "async def a_download_by_url(\n",
        "    url: str,\n",
        "    target_file_path: str,\n",
        "    chunk_size: int = 1024\n",
        ") -> None:\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.get(url) as response:\n",
        "            with open(target_file_path, \"wb\") as handle:\n",
        "                async for data in response.content.iter_chunked(chunk_size):\n",
        "                    handle.write(data)\n",
        "\n",
        "\n",
        "await a_download_by_url('https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar', '/content/navec_news_v1_1B_250K_300d_100q.tar')\n",
        "await a_download_by_url('https://storage.yandexcloud.net/natasha-slovnet/packs/slovnet_morph_news_v1.tar',         '/content/slovnet_morph_news_v1.tar')\n",
        "await a_download_by_url('https://storage.yandexcloud.net/natasha-slovnet/packs/slovnet_syntax_news_v1.tar',        '/content/slovnet_syntax_news_v1.tar')\n",
        "\n",
        "navec  = Navec.load('/content/navec_news_v1_1B_250K_300d_100q.tar')\n",
        "morph  = Morph.load('/content/slovnet_morph_news_v1.tar', batch_size=4)\n",
        "syntax = Syntax.load('/content/slovnet_syntax_news_v1.tar')\n",
        "\n",
        "morph.navec(navec)\n",
        "syntax.navec(navec)\n",
        "pass"
      ],
      "metadata": {
        "id": "imePv-NX5Qmj"
      },
      "id": "imePv-NX5Qmj",
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "5abce709-925c-405c-83ab-4b7ea0928abc",
      "metadata": {
        "scrolled": true,
        "id": "5abce709-925c-405c-83ab-4b7ea0928abc"
      },
      "outputs": [],
      "source": [
        "@dataclass(eq = True, frozen = True)\n",
        "class Word:\n",
        "    '''\n",
        "    Класс для отображения информации о слове.\n",
        "\n",
        "    Attributes:\n",
        "        id (int): Индекс слова в предложении.\n",
        "        word (str): Строковое представление слова.\n",
        "        morph (str): Морфологический тип слова (например: ADV, NOUN или PUNCT).\n",
        "    '''\n",
        "    id: int\n",
        "    word: str\n",
        "    morph: str\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word)\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.word\n",
        "\n",
        "    def ljust(self, size: int):\n",
        "        return self.word.ljust(size)\n",
        "\n",
        "@dataclass\n",
        "class Collocation:\n",
        "    '''\n",
        "    Класс для отображения коллокации двух слов (слова и знака пунктуации) с указанием типа связи.\n",
        "\n",
        "    Attributes:\n",
        "        source_word (Word): Слово, которое определяет связь.\n",
        "        target_word (Word): Слово, являющееся объетом связи.\n",
        "        rel (str): Тип связи между source_word и target_word, (например: conj, case, iobj, punct и т.д.)\n",
        "    '''\n",
        "    source_word: Word\n",
        "    target_word: Word\n",
        "    rel: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "353e1e21-0363-44be-9ab5-5af6e1307d61",
      "metadata": {
        "id": "353e1e21-0363-44be-9ab5-5af6e1307d61"
      },
      "outputs": [],
      "source": [
        "def collocations(text: str) -> list[Collocation]:\n",
        "    '''\n",
        "    Разбивает исходный текст на коллокации (словосочетания, имеющее признаки синтаксически и семантически целостной единицы)\n",
        "\n",
        "    Args:\n",
        "        text (str): Текст с пунктуацией и сохраненным регистром.\n",
        "\n",
        "    Returns:\n",
        "        collocations (list[Collocation]): список коллокаций (каждая коллокация представлена парой слов и типом связи)\n",
        "    '''\n",
        "\n",
        "    tokens = tokenize(text)\n",
        "    chunk = [[_.text for _ in tokens]]\n",
        "\n",
        "    syntax_markup = syntax.map(chunk)\n",
        "    morph_markup = morph.map(chunk)\n",
        "\n",
        "    collocations = list()\n",
        "\n",
        "    morph_tags = dict()\n",
        "    for token in next(morph_markup).tokens:\n",
        "\n",
        "        tag_name_end = token.tag.find('|')\n",
        "        token_tag = token.tag[:tag_name_end]\n",
        "\n",
        "        if not token.text in morph_tags:\n",
        "            morph_tags[token.text] = token_tag\n",
        "\n",
        "    for token in next(syntax_markup).tokens:\n",
        "        source = int(token.head_id) - 1\n",
        "        target = int(token.id) - 1\n",
        "\n",
        "        source_word_text = chunk[0][source]\n",
        "        target_word_text = chunk[0][target]\n",
        "\n",
        "        if source > 0 and source != target:  # skip root, loops\n",
        "\n",
        "            source_morph = morph_tags[source_word_text]\n",
        "            target_morph = morph_tags[target_word_text]\n",
        "\n",
        "            source_word = Word(\n",
        "                id=source,\n",
        "                word=source_word_text,\n",
        "                morph=source_morph\n",
        "            )\n",
        "\n",
        "            target_word = Word(\n",
        "                id=target,\n",
        "                word=target_word_text,\n",
        "                morph=target_morph\n",
        "            )\n",
        "\n",
        "            collocation = Collocation(\n",
        "                source_word=source_word,\n",
        "                target_word=target_word,\n",
        "                rel = token.rel\n",
        "            )\n",
        "\n",
        "            collocations.append(collocation)\n",
        "\n",
        "    return collocations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "c359d202-7c0e-4332-8348-a05315527af5",
      "metadata": {
        "id": "c359d202-7c0e-4332-8348-a05315527af5"
      },
      "outputs": [],
      "source": [
        "def _restore_words_order(collocations: list[Collocation]) -> list[str]:\n",
        "    used_id = []\n",
        "    words = []\n",
        "\n",
        "    for colloc in collocations:\n",
        "        words.append(colloc.source_word)\n",
        "        words.append(colloc.target_word)\n",
        "\n",
        "    sorted_words = sorted(words, key=lambda word: word.id)\n",
        "\n",
        "    ordered_words = []\n",
        "    prev_id = None\n",
        "    for word in sorted_words:\n",
        "        if word.id != prev_id:\n",
        "            ordered_words.append(word)\n",
        "            prev_id = word.id\n",
        "\n",
        "    return ordered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "8a4b2b60-33b3-4011-8b37-6a71e7be8ca5",
      "metadata": {
        "id": "8a4b2b60-33b3-4011-8b37-6a71e7be8ca5"
      },
      "outputs": [],
      "source": [
        "def show_collocations_deps(\n",
        "    collocations: list[Collocation],\n",
        "    ignore: list[str] = []\n",
        ") -> None:\n",
        "    '''\n",
        "    Отображает в stdout схему\n",
        "\n",
        "    Args:\n",
        "        collocations (list[Collocation]): список коллокаций (каждая коллокация представлена парой слов и типом связи)\n",
        "    '''\n",
        "\n",
        "    words = _restore_words_order(collocations)\n",
        "\n",
        "    deps = []\n",
        "    for colloc in collocations:\n",
        "        if colloc.rel not in ignore:\n",
        "\n",
        "            deps.append(\n",
        "                [colloc.source_word.id,\n",
        "                 colloc.target_word.id, colloc.rel]\n",
        "            )\n",
        "    show_markup(words, deps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "6fbca03c-e98e-49a1-80f7-5c1c1b51e99c",
      "metadata": {
        "id": "6fbca03c-e98e-49a1-80f7-5c1c1b51e99c"
      },
      "outputs": [],
      "source": [
        "def filter_collocations(\n",
        "    collocations: list[Collocation],\n",
        "    rels_to_remove: list[str]\n",
        ") -> list[Collocation]:\n",
        "\n",
        "    def good_collocation(collocation: Collocation) -> bool:\n",
        "        return collocation.rel not in rels_to_remove\n",
        "\n",
        "    filtered = filter(good_collocation,\n",
        "                      collocations)\n",
        "\n",
        "    return list(filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "508cf0fa-9f5b-48de-8986-fcf0fcb2408c",
      "metadata": {
        "id": "508cf0fa-9f5b-48de-8986-fcf0fcb2408c"
      },
      "outputs": [],
      "source": [
        "def prune_text(text: str, rejected_rels: list[str], show_steps: bool = False) -> str:\n",
        "    '''\n",
        "    Убирает из текста те слова, которые находятся в фильтруемых коллокациях.\n",
        "    Коллокации фильтруются по синтаксическим отношениям между двумя словами коллокации.\n",
        "\n",
        "    Args:\n",
        "        text (str): Текст с пунктуацией и сохраненным регистром.\n",
        "        rejected_rels (list[str]): список типов синтаксических отношений, которые нужно ислючить из текста (['punct', 'discourse'])\n",
        "        (Optional) show_steps (bool): Выводить ли в stdout выделенные коллокации и отфильтрованные слова.\n",
        "    Returns:\n",
        "        text (str): отфильтрованный текст с сохранением исходного порядка слов.\n",
        "    '''\n",
        "\n",
        "    colls = filter_collocations(collocations(text), rejected_rels)\n",
        "\n",
        "    if show_steps:\n",
        "        pprint(colls, indent=4)\n",
        "\n",
        "    words_order = _restore_words_order(colls)\n",
        "\n",
        "    if show_steps:\n",
        "        pprint(words_order, indent=4)\n",
        "\n",
        "    words = list(map(str, words_order))\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "62e87b1d-6474-4e74-b637-1cd40f6cc980",
      "metadata": {
        "id": "62e87b1d-6474-4e74-b637-1cd40f6cc980"
      },
      "outputs": [],
      "source": [
        "def get_rels_list(collocations: list) -> list:\n",
        "    rels = list()\n",
        "    for col in collocations:\n",
        "        rels.append(col.rel)\n",
        "    return rels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "03187970-1230-4df3-8eee-8dfb0b286a40",
      "metadata": {
        "id": "03187970-1230-4df3-8eee-8dfb0b286a40"
      },
      "outputs": [],
      "source": [
        "def count_rels(text: str) -> dict:\n",
        "  colls = collocations(text)\n",
        "  rels = get_rels_list(colls)\n",
        "  return dict(Counter(rels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TextStat:\n",
        "    text: str\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.nb = self.count_letters()\n",
        "        self.ns = self.count_words()\n",
        "        self.np = self.count_sentences()\n",
        "        self.colls = self.count_collocations()\n",
        "\n",
        "    def count_letters(self) -> int:\n",
        "        \"\"\"Подсчитывает количество букв в тексте.\"\"\"\n",
        "        return sum(1 for char in self.text if char.isalpha())\n",
        "\n",
        "    def count_words(self) -> int:\n",
        "        \"\"\"Подсчитывает количество слов в тексте.\"\"\"\n",
        "        return len(self.text.split())\n",
        "\n",
        "    def count_sentences(self) -> int:\n",
        "        \"\"\"Подсчитывает количество предложений в тексте.\"\"\"\n",
        "        predicates = re.split(r'[.!?]+', self.text.strip())\n",
        "        return len([p for p in predicates if p.strip()])  # Учитываем только непустые предложения\n",
        "\n",
        "    def count_collocations(self) -> int:\n",
        "        \"\"\"Подсчитывает количество семантических отношений.\"\"\"\n",
        "        return len(collocations(self.text))\n",
        "\n",
        "    def average_word_length(self, n_round: int = 2) -> float:\n",
        "        \"\"\"Возвращает среднюю длину слова в тексте.\"\"\"\n",
        "        return round(self.nb / self.ns, n_round) if self.ns > 0 else 0.0\n",
        "\n",
        "    def average_sentence_length(self, n_round: int = 2) -> float:\n",
        "        \"\"\"Возвращает среднюю длину предложения в тексте.\"\"\"\n",
        "        return round(self.ns / self.np, n_round) if self.np > 0 else 0.0\n",
        "\n",
        "    def letters_per_collocation(self, n_round: int = 2) -> float:\n",
        "        \"\"\"Возвращает количество букв на семантическое отношение.\"\"\"\n",
        "        return round(self.nb / self.colls, n_round) if self.colls > 0 else 0.0\n",
        "\n",
        "    def collocations_per_word(self, n_round: int = 2) -> float:\n",
        "        \"\"\"Возвращает количество семантических отношений на слово.\"\"\"\n",
        "        return round(self.colls / self.ns, n_round) if self.ns > 0 else 0.0\n",
        "\n",
        "    def collocations_per_sentence(self, n_round: int = 2) -> float:\n",
        "        \"\"\"Возвращает количество семантических отношений на предложение.\"\"\"\n",
        "        return round(self.colls / self.np, n_round) if self.np > 0 else 0.0\n",
        "\n",
        "    def __str__(self):\n",
        "        return (f\"Количество букв в тексте: {self.nb}\\n\"\n",
        "                f\"Количество слов в тексте: {self.ns}\\n\"\n",
        "                f\"Количество предложений: {self.np}\\n\"\n",
        "                f\"Ср. длина слова: {self.average_word_length()}\\n\"\n",
        "                f\"Ср. длина предложения: {self.average_sentence_length()}\\n\"\n",
        "                f\"Кол-во сем. отношений: {self.colls}\\n\"\n",
        "                f\"Букв на сем. отношение: {self.letters_per_collocation()}\\n\"\n",
        "                f\"Сем. отношений на слово: {self.collocations_per_word()}\\n\"\n",
        "                f\"Сем. отношений на предложение: {self.collocations_per_sentence()}\")"
      ],
      "metadata": {
        "id": "0-2JWVaDc9x6"
      },
      "id": "0-2JWVaDc9x6",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Одним из внезапных итогов Петербургского международного экономического форума 2024 года\n",
        "стало практическое отсутствие ставших уже привычными громких заявлений о намерении\n",
        "произвести в ближайшие годы все новые сотни гражданских самолетов.\n",
        "Сообщение о запуске авиашаттла между Москвой и Санкт-Петербургом лишь незначительно компенсировало эту оглушающую тишину.\n",
        "Конечно, «громадье планов» неумолимо сокращалось по мере столкновения журналистов, социологов, экономистов и прочих пиарщиков,\n",
        "которым поручили составлять и реализовывать эти планы, с загадочной для них технологической реальностью.\n",
        "Однако полное прекращение радостных сообщений о том, что единственный экземпляр очередного самолета теперь надо официально именовать «серийным», вызвало интерес и привлекло к себе внимание.\n",
        "Причина проста: внезапно оказалось, что за весь 2023 год российское гражданское авиастроение,\n",
        "крайне успешно и эффектно «поднимаемое с колен» теми же самыми эффективными менеджерами, которые ставили его на эти колени долгие годы, произвело аж 9 самолетов.\n",
        "\"\"\"\n",
        "\n",
        "text_stat = TextStat(text)\n",
        "\n",
        "rels_list = set(get_rels_list(collocations(text)))\n",
        "rels_count = count_rels(text)\n",
        "\n",
        "print(text_stat)\n",
        "\n",
        "print('\\nСписок синтакс. отношений, извлеченных из текста:')\n",
        "pprint(rels_list, indent=4)\n",
        "\n",
        "print('\\nЧастота представленности синтакс. отношений, извлеченных из текста:')\n",
        "pprint(rels_count, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEh0smnXfVLU",
        "outputId": "d69d8ac2-1136-4d4e-ec66-4463e052b285"
      },
      "id": "sEh0smnXfVLU",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество букв в тексте: 875\n",
            "Количество слов в тексте: 130\n",
            "Количество предложений: 5\n",
            "Ср. длина слова: 6.73\n",
            "Ср. длина предложения: 26.0\n",
            "Кол-во сем. отношений: 148\n",
            "Букв на сем. отношение: 5.91\n",
            "Сем. отношений на слово: 1.14\n",
            "Сем. отношений на предложение: 29.6\n",
            "\n",
            "Список синтакс. отношений, извлеченных из текста:\n",
            "{   'acl',\n",
            "    'acl:relcl',\n",
            "    'advmod',\n",
            "    'amod',\n",
            "    'case',\n",
            "    'cc',\n",
            "    'ccomp',\n",
            "    'conj',\n",
            "    'csubj',\n",
            "    'det',\n",
            "    'fixed',\n",
            "    'iobj',\n",
            "    'mark',\n",
            "    'nmod',\n",
            "    'nsubj',\n",
            "    'nummod',\n",
            "    'obj',\n",
            "    'obl',\n",
            "    'parataxis',\n",
            "    'punct',\n",
            "    'xcomp'}\n",
            "\n",
            "Частота представленности синтакс. отношений, извлеченных из текста:\n",
            "{   'acl': 5,\n",
            "    'acl:relcl': 2,\n",
            "    'advmod': 12,\n",
            "    'amod': 24,\n",
            "    'case': 13,\n",
            "    'cc': 5,\n",
            "    'ccomp': 2,\n",
            "    'conj': 7,\n",
            "    'csubj': 1,\n",
            "    'det': 6,\n",
            "    'fixed': 1,\n",
            "    'iobj': 1,\n",
            "    'mark': 2,\n",
            "    'nmod': 12,\n",
            "    'nsubj': 8,\n",
            "    'nummod': 2,\n",
            "    'obj': 7,\n",
            "    'obl': 10,\n",
            "    'parataxis': 3,\n",
            "    'punct': 23,\n",
            "    'xcomp': 2}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}